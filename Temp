#!/usr/bin/env python

import cv2
import numpy as np

# ========================= Student's code starts here =========================

# Params for camera calibration
theta = 0.176
beta = 752.21      #10m apart
tx = 0.2571
ty = 0.062

# Global variables for accumulating keypoints across colors
global_all_keypoints = []
global_all_colors = []

# Function that converts image coord to world coord
def IMG2W(col, row):
    O_r = 240       #from Figure B.2
    O_c = 320

    x_c = (col - O_c) / beta
    y_c = (O_r - row) / beta        #since y increases when it goes down, we have to flip y

    x_w = x_c * np.cos(theta) - y_c * np.sin(theta) + tx
    y_w = x_c * np.sin(theta) + y_c * np.cos(theta) + ty

    return (x_w, y_w)

# ========================= Student's code ends here ===========================

def blob_search(image_raw, color):
    # Clear previous keypoints at the start of each frame
    if color == "green":  # Clear when processing the first color
        global_all_keypoints.clear()
        global_all_colors.clear()

    # Setup SimpleBlobDetector parameters.
    params = cv2.SimpleBlobDetector_Params()

    # ========================= Student's code starts here =========================

    # Filter by Color
    params.filterByColor = False

    # Filter by Area - ADJUSTED FOR BETTER DETECTION
    params.filterByArea = True
    params.minArea = 150      # Increased to avoid small noise
    params.maxArea = 5000     # Increased for larger blocks

    # Filter by Circularity
    params.filterByCircularity = False

    # Filter by Inertia
    params.filterByInertia = False

    # Filter by Convexity
    params.filterByConvexity = False

    # ========================= Student's code ends here ===========================

    # Create a detector with the parameters
    detector = cv2.SimpleBlobDetector_create(params)

    # Convert the image into the HSV color space
    hsv_image = cv2.cvtColor(image_raw, cv2.COLOR_BGR2HSV)

    # ========================= Student's code starts here =========================

    # Define colors with proper BGR values and improved blue range
    if color == "orange":
        lower = (5, 100, 100)
        upper = (15, 255, 255)
        color_bgr = (0, 165, 255)  # Orange
        mask_image = cv2.inRange(hsv_image, lower, upper)
        
    elif color == "green":
        lower = (40, 50, 50)
        upper = (90, 255, 255)
        color_bgr = (0, 255, 0)    # Green
        mask_image = cv2.inRange(hsv_image, lower, upper)
        
    elif color == "blue":
        # WIDER BLUE RANGE to catch all blue blocks
        lower = (90, 50, 50)       # Lower hue for more blue shades
        upper = (140, 255, 255)    # Higher hue for more blue shades
        color_bgr = (255, 0, 0)    # Blue
        mask_image = cv2.inRange(hsv_image, lower, upper)
        
        # MORPHOLOGICAL OPERATIONS FOR BLUE ONLY - to connect incomplete blobs
        kernel = np.ones((9, 9), np.uint8)  # Larger kernel for blue
        mask_image = cv2.morphologyEx(mask_image, cv2.MORPH_CLOSE, kernel)  # Fill gaps
        mask_image = cv2.morphologyEx(mask_image, cv2.MORPH_OPEN, kernel)   # Remove noise
        
    else:
        lower = (5, 100, 100)
        upper = (15, 255, 255)
        color_bgr = (0, 165, 255)
        mask_image = cv2.inRange(hsv_image, lower, upper)

    # ========================= Student's code ends here ===========================

    # Detect keypoints
    keypoints = detector.detect(mask_image)

    # ========================= Student's code starts here =========================

    # FILTER KEYPOINTS - Only add if they correspond to actual mask regions
    filtered_keypoints = []
    for kp in keypoints:
        x, y = int(kp.pt[0]), int(kp.pt[1])
        # Check if the keypoint is in a white region of the mask
        if 0 <= y < mask_image.shape[0] and 0 <= x < mask_image.shape[1]:
            if mask_image[y, x] > 0:  # Only add if it's actually in a masked area
                filtered_keypoints.append(kp)
    
    # Add filtered keypoints to global lists
    for kp in filtered_keypoints:
        global_all_keypoints.append(kp)
        global_all_colors.append(color_bgr)

    # Create combined mask for display (shows all colors)
    combined_mask = np.zeros_like(mask_image)
    
    # Define color ranges for combined mask
    color_ranges = {
        "orange": ((5, 100, 100), (15, 255, 255)),
        "green": ((40, 50, 50), (90, 255, 255)),
        "blue": ((90, 50, 50), (140, 255, 255))  # Wider blue range for mask view too
    }

    for color_name, (lower, upper) in color_ranges.items():
        color_mask = cv2.inRange(hsv_image, lower, upper)
        
        # Apply morphological operations only for blue in combined mask
        if color_name == "blue":
            kernel = np.ones((9, 9), np.uint8)
            color_mask = cv2.morphologyEx(color_mask, cv2.MORPH_CLOSE, kernel)
            color_mask = cv2.morphologyEx(color_mask, cv2.MORPH_OPEN, kernel)
            
        combined_mask = cv2.bitwise_or(combined_mask, color_mask)

    # Draw ALL accumulated keypoints from all colors
    im_with_keypoints = image_raw.copy()
    for kp, col in zip(global_all_keypoints, global_all_colors):
        im_with_keypoints = cv2.drawKeypoints(im_with_keypoints, [kp], np.array([]), col, cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

    # ========================= Student's code ends here ===========================

    # Find blob centers in the image coordinates (using filtered keypoints)
    blob_image_center = []
    num_blobs = len(filtered_keypoints)
    for i in range(num_blobs):
        blob_image_center.append((filtered_keypoints[i].pt[0], filtered_keypoints[i].pt[1]))

    xw_yw = []

    if(num_blobs == 0):
        print(f"No {color} block found!")
    else:
        # Convert image coordinates to global world coordinate using IM2W() function
        for i in range(num_blobs):
            xw_yw.append(IMG2W(blob_image_center[i][0], blob_image_center[i][1]))

    cv2.namedWindow("Camera View")
    cv2.imshow("Camera View", image_raw)
    cv2.namedWindow("Mask View")
    cv2.imshow("Mask View", combined_mask)
    cv2.namedWindow("Keypoint View")
    cv2.imshow("Keypoint View", im_with_keypoints)

    cv2.waitKey(2)

    return xw_yw
